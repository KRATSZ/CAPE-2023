{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2312c0ff",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d31fec",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655c5a55",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# constant & dataframe\n",
    "\n",
    "prime_seq = \"RAQLSQ\"\n",
    "cite_list = ['74', '101', '143', '148', '173', '176']\n",
    "aa_order = ['L', 'S', 'E', 'A', 'G', 'P', 'V', 'K', 'R', 'T', 'D', 'Q', 'I', 'F', 'N', 'Y', 'H', 'C', 'M', 'W']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7470b668",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_df = pd.read_csv('Mut_compe/training.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4acadd4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "row_3L = training_df[training_df['Sequence'] == \"RALLSQ\"]\n",
    "row_3R = training_df[training_df['Sequence'] == \"RARLSQ\"]\n",
    "row_3V = training_df[training_df['Sequence'] == \"RAVLSQ\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ee3b33",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# suppose the missing value\n",
    "k1,k2 = 0.05,0.1\n",
    "\n",
    "training_df.loc[len(training_df)] = [1594,\"RAILSQ\", (row_3L['Activity'].values[0]+row_3V['Activity'].values[0])*0.5, row_3L['Selectivity'].values[0]+k1]\n",
    "training_df.loc[len(training_df)] = [1595,\"RAKLSQ\", row_3R['Activity'].values[0]+k1, row_3R['Selectivity'].values[0]+k2]\n",
    "training_df.loc[len(training_df)] = [1596,\"RAMLSQ\", row_3V['Activity'].values[0]*0.5 + 0.5, row_3L['Selectivity'].values[0]*0.5+0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783c96df",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_df['lg_Act'] = np.log(training_df['Activity'])\n",
    "training_df['lg_Sel'] = np.log(training_df['Selectivity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded6f4e0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0882b02",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_df[training_df['Selectivity'] == 8.816]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6d6951",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.scatter(training_df['Activity'],training_df['Selectivity'])\n",
    "plt.show()\n",
    "plt.scatter(training_df['lg_Act'],training_df['lg_Sel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c64c9f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_mut_description(col_index, mut_aa):\n",
    "    if mut_aa == prime_seq[col_index]:\n",
    "        return \"\"\n",
    "    else:\n",
    "        return f\"S{prime_seq[col_index]}{cite_list[col_index]}{mut_aa}:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b946a049",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_seq_description(seq):\n",
    "    disc = \"\"\n",
    "    for i in range(6):\n",
    "        disc += get_mut_description(i, seq[i])\n",
    "    if len(disc) > 0:\n",
    "        return disc[:-1]\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e1cbfe",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_df['description'] = training_df['Sequence'].apply(lambda x:get_seq_description(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9765ee90",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "2. prepare the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327e709c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "from https://github.com/usnistgov/lantern.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ecce2c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predata_act = training_df[['description', 'lg_Act']]\n",
    "predata_sel = training_df[['description', 'lg_Sel']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba158261",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predata_act.columns = ['substitutions', 'phenotype']\n",
    "predata_sel.columns = ['substitutions', 'phenotype']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be73fec6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lantern.dataset import Dataset\n",
    "ds_act = Dataset(predata_act)\n",
    "ds_act"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e3337d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "3. build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6022053",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "K_act = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c44e8b2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lantern.model.basis import VariationalBasis\n",
    "\n",
    "basis_act = VariationalBasis.fromDataset(ds_act, K=K_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77d55a4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lantern.model.surface import Phenotype\n",
    "\n",
    "surface_act = Phenotype.fromDataset(ds_act, K=K_act, Ni=200, inducScale=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807acf24",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lantern.model import Model\n",
    "from lantern.model.likelihood import GaussianLikelihood\n",
    "\n",
    "model_act = Model(basis_act, surface_act, GaussianLikelihood())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5330a2a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "4. train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fdc825",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "loss_act = model_act.loss(N=len(ds_act))\n",
    "Xtrain, ytrain = ds_act[: len(ds_act)]\n",
    "\n",
    "E = 3000\n",
    "optimizer_act = Adam(loss_act.parameters(), lr=0.01)\n",
    "hist_act = []\n",
    "halpha = np.zeros((E, K_act))\n",
    "\n",
    "for i in range(E):\n",
    "    \n",
    "    optimizer_act.zero_grad()\n",
    "    yhat = model_act(Xtrain)\n",
    "    lss_act = loss_act(yhat, ytrain)\n",
    "    total_act = sum(lss_act.values())\n",
    "    total_act.backward()\n",
    "    optimizer_act.step()\n",
    "    \n",
    "    hist_act.append(total_act.item())\n",
    "    halpha[i, :] = basis_act.qalpha(detach=True).mean.numpy()\n",
    "    \n",
    "\n",
    "plt.figure(figsize=(4, 3), dpi=300)\n",
    "plt.plot(hist_act)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss_act\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820521bb",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 3), dpi=300)\n",
    "plt.plot(1/halpha)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"variance_act\")\n",
    "plt.semilogy()\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a10ac8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "5. analyze the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18165356",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The dimensionality calculations require the trained model and dataset. The number displayed as output is the total number of dimensions found in the model (this is also available as the attribute `K` of the returned `Dimensionality` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5ed366",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lantern.model import dimensionality\n",
    "\n",
    "dim_act = dimensionality(model_act, ds_act)\n",
    "dim_act"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063f5517",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To view the statistics used to determine the dimensionality (see LANTERN's associated manuscript for more details), there is a diagnostic plot available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf34a89",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dim_act.plotStatistics(nrow=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e4d5fb",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Finally, to see the variance learned for each dimension (with circles representing dimensions included according to the determined dimensionality), run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531d83e4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dim_act.plotVariance(model_act.basis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8adb1a3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "2. prepare the model(sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6fbe5a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lantern.dataset import Dataset\n",
    "ds_sel = Dataset(predata_sel)\n",
    "ds_sel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2597ffe9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "3. build the model(sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f940be7b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "K_sel = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9675f201",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lantern.model.basis import VariationalBasis\n",
    "\n",
    "basis_sel = VariationalBasis.fromDataset(ds_sel, K=K_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877da32b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lantern.model.surface import Phenotype\n",
    "\n",
    "surface_sel = Phenotype.fromDataset(ds_sel, K=K_sel, Ni=200, inducScale=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5805e27e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lantern.model import Model\n",
    "from lantern.model.likelihood import GaussianLikelihood\n",
    "\n",
    "model_sel = Model(basis_sel, surface_sel, GaussianLikelihood())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d7580d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "4. train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0ce943",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "loss_sel = model_sel.loss(N=len(ds_sel))\n",
    "Xtrain2, ytrain2 = ds_sel[: len(ds_sel)]\n",
    "\n",
    "E = 3000\n",
    "optimizer_sel = Adam(loss_sel.parameters(), lr=0.01)\n",
    "hist_sel = []\n",
    "halpha2 = np.zeros((E, K_sel))\n",
    "\n",
    "for i in range(E):\n",
    "    \n",
    "    optimizer_sel.zero_grad()\n",
    "    yhat = model_sel(Xtrain2)\n",
    "    lss = loss_sel(yhat, ytrain2)\n",
    "    total_sel = sum(lss.values())\n",
    "    total_sel.backward()\n",
    "    optimizer_sel.step()\n",
    "    \n",
    "    hist_sel.append(total_sel.item())\n",
    "    halpha2[i, :] = basis_sel.qalpha(detach=True).mean.numpy()\n",
    "    \n",
    "plt.figure(figsize=(4, 3), dpi=300)\n",
    "plt.plot(hist_sel)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss_sel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2706e3b8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 3), dpi=300)\n",
    "plt.plot(1/halpha2)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"variance_sel\")\n",
    "plt.semilogy()\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa875f98",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dim_sel = dimensionality(model_sel, ds_sel)\n",
    "dim_sel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660cef7f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To view the statistics used to determine the dimensionality (see LANTERN's associated manuscript for more details), there is a diagnostic plot available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be912e5b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dim_sel.plotStatistics(nrow=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8b0ca4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Finally, to see the variance learned for each dimension (with circles representing dimensions included according to the determined dimensionality), run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c220cecc",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dim_sel.plotVariance(model_sel.basis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c54bf74",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "5 Evaluate the model(act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de9a03f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# find z1, z2\n",
    "z1, z2 = model_act.basis.order[:2]\n",
    "\n",
    "# get mutations and brightness for all observations\n",
    "X, y = ds_act[:len(ds_act)]\n",
    "\n",
    "# get the embedding for all data points\n",
    "with torch.no_grad():\n",
    "    Z = model_act.basis(X)\n",
    "\n",
    "# to filter outliers, only plot the points within [q/2, 1-q/2] quantile of each latent dimension\n",
    "q = 0.01\n",
    "\n",
    "# number of surface points\n",
    "N = 100\n",
    "\n",
    "# the meshgrid is used for surface plotting\n",
    "Z1, Z2 = np.meshgrid(\n",
    "    np.linspace(np.quantile(Z[:, z1], q/2), np.quantile(Z[:, z1], 1 - q/2), N),\n",
    "    np.linspace(np.quantile(Z[:, z2], q/2), np.quantile(Z[:, z2], 1 - q/2), N )\n",
    ")\n",
    "\n",
    "# predict the surface at each meshgrid point\n",
    "Zpred = torch.zeros(N**2, model_act.basis.K)\n",
    "Zpred[:, z1] = torch.from_numpy(Z1.ravel())\n",
    "Zpred[:, z2] = torch.from_numpy(Z2.ravel())\n",
    "\n",
    "# predict the surface\n",
    "with torch.no_grad():\n",
    "    fpred = model_act.surface(Zpred)\n",
    "    \n",
    "# scale to original brightness values and reshape for plotting\n",
    "f = fpred.mean * predata_act[\"phenotype\"].std() + predata_act[\"phenotype\"].mean()\n",
    "f = f.reshape(Z1.shape)\n",
    "\n",
    "# also scale the data for plotting\n",
    "y = y * predata_act[\"phenotype\"].std() + predata_act[\"phenotype\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97690efe",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3,2), dpi=300)\n",
    "\n",
    "im = plt.contourf(Z1, Z2, f, levels=8)\n",
    "plt.xlabel(\"$z_1$\")\n",
    "plt.ylabel(\"$z_2$\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b42332",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3,2), dpi=300)\n",
    "\n",
    "im = plt.contour(Z1, Z2, f, levels=8)\n",
    "plt.scatter(Z[:, z1].numpy(), Z[:, z2].numpy(), c = y, alpha=0.8, s=0.3, rasterized=True)\n",
    "\n",
    "# re-apply the limits\n",
    "plt.xlim(np.quantile(Z[:, z1], q/2), np.quantile(Z[:, z1], 1 - q/2))\n",
    "plt.ylim(np.quantile(Z[:, z2], q/2), np.quantile(Z[:, z2], 1 - q/2))\n",
    "\n",
    "plt.xlabel(\"$z_1$\")\n",
    "plt.ylabel(\"$z_2$\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39584c94",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "5. Evaluate the model(sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ababd4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# find z1, z2\n",
    "z1, z2 = model_sel.basis.order[:2]\n",
    "\n",
    "# get mutations and brightness for all observations\n",
    "X, y = ds_sel[:len(ds_sel)]\n",
    "\n",
    "# get the embedding for all data points\n",
    "with torch.no_grad():\n",
    "    Z = model_sel.basis(X)\n",
    "\n",
    "# to filter outliers, only plot the points within [q/2, 1-q/2] quantile of each latent dimension\n",
    "q = 0.01\n",
    "\n",
    "# number of surface points\n",
    "N = 100\n",
    "\n",
    "# the meshgrid is used for surface plotting\n",
    "Z1, Z2 = np.meshgrid(\n",
    "    np.linspace(np.quantile(Z[:, z1], q/2), np.quantile(Z[:, z1], 1 - q/2), N),\n",
    "    np.linspace(np.quantile(Z[:, z2], q/2), np.quantile(Z[:, z2], 1 - q/2), N )\n",
    ")\n",
    "\n",
    "# predict the surface at each meshgrid point\n",
    "Zpred = torch.zeros(N**2, model_sel.basis.K)\n",
    "Zpred[:, z1] = torch.from_numpy(Z1.ravel())\n",
    "Zpred[:, z2] = torch.from_numpy(Z2.ravel())\n",
    "\n",
    "# predict the surface\n",
    "with torch.no_grad():\n",
    "    fpred = model_sel.surface(Zpred)\n",
    "    \n",
    "# scale to original brightness values and reshape for plotting\n",
    "f = fpred.mean * predata_sel[\"phenotype\"].std() + predata_sel[\"phenotype\"].mean()\n",
    "f = f.reshape(Z1.shape)\n",
    "\n",
    "# also scale the data for plotting\n",
    "y = y * predata_sel[\"phenotype\"].std() + predata_sel[\"phenotype\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73fcf74",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3,2), dpi=300)\n",
    "\n",
    "im = plt.contourf(Z1, Z2, f, levels=8)\n",
    "plt.xlabel(\"$z_1$\")\n",
    "plt.ylabel(\"$z_2$\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397cf5c3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3,2), dpi=300)\n",
    "\n",
    "im = plt.contour(Z1, Z2, f, levels=8)\n",
    "plt.scatter(Z[:, z1].numpy(), Z[:, z2].numpy(), c = y, alpha=0.8, s=0.3, rasterized=True)\n",
    "\n",
    "# re-apply the limits\n",
    "plt.xlim(np.quantile(Z[:, z1], q/2), np.quantile(Z[:, z1], 1 - q/2))\n",
    "plt.ylim(np.quantile(Z[:, z2], q/2), np.quantile(Z[:, z2], 1 - q/2))\n",
    "\n",
    "plt.xlabel(\"$z_1$\")\n",
    "plt.ylabel(\"$z_2$\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee41ffa",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "6.to Predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a03f1a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_set = pd.read_csv('Mut_compe/test.csv', sep = ',')\n",
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123f3bb3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_set['description'] = test_set['Sequence'].apply(lambda x:get_seq_description(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf92872",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_pre = torch.stack([ds_act.tokenizer.tokenize(x) for x in test_set['description']])\n",
    "\n",
    "with torch.no_grad():\n",
    "    Z_preact = model_act.basis(X_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28262ce0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_of_tensors = [ds_act.tokenizer.tokenize(x) for x in test_set['description']]\n",
    "X_pre = torch.stack(list_of_tensors)\n",
    "\n",
    "with torch.no_grad():\n",
    "    Z_presel = model_sel.basis(X_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3481f47a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# to filter outliers, only plot the points within [q/2, 1-q/2] quantile of each latent dimension\n",
    "q = 0.01\n",
    "\n",
    "# number of surface points\n",
    "N = 100\n",
    "\n",
    "# the meshgrid is used for surface plotting\n",
    "Z1, Z2 = np.meshgrid(\n",
    "    np.linspace(np.quantile(Z_presel[:, z1], q/2), np.quantile(Z_presel[:, z1], 1 - q/2), N),\n",
    "    np.linspace(np.quantile(Z_presel[:, z2], q/2), np.quantile(Z_presel[:, z2], 1 - q/2), N )\n",
    ")\n",
    "\n",
    "# predict the surface at each meshgrid point\n",
    "Zpred = torch.zeros(N**2, model_sel.basis.K)\n",
    "Zpred[:, z1] = torch.from_numpy(Z1.ravel())\n",
    "Zpred[:, z2] = torch.from_numpy(Z2.ravel())\n",
    "\n",
    "# predict the surface\n",
    "with torch.no_grad():\n",
    "    fpred = model_sel.surface(Zpred)\n",
    "    \n",
    "# scale to original brightness values and reshape for plotting\n",
    "f = fpred.mean * predata_sel['phenotype'].std() + predata_sel['phenotype'].mean()\n",
    "f = f.reshape(Z1.shape)\n",
    "\n",
    "# also scale the data for plotting\n",
    "y = y * predata_sel['phenotype'].std() + predata_sel['phenotype'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af12f8e3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3,2), dpi=300)\n",
    "\n",
    "im = plt.contourf(Z1, Z2, f, levels=8)\n",
    "plt.xlabel(\"$z_1$\")\n",
    "plt.ylabel(\"$z_2$\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41a9c87",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next, we add the scatter of measured datapoints for comparison, coloring them by their measured value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fafb83",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_act, y_act = ds_act[:len(ds_act)]\n",
    "\n",
    "with torch.no_grad():\n",
    "    Z_act = model_act.basis(X_act)\n",
    "    Zpred = torch.zeros(len(Z_act), K_act)\n",
    "    for i in model_act.basis.order[:2]:\n",
    "        Zpred[:, i] = Z_act[:,i]\n",
    "\n",
    "with torch.no_grad():\n",
    "    f_act = model_act.surface(Zpred)\n",
    "\n",
    "with torch.no_grad():\n",
    "    Y = f_act.mean.numpy()\n",
    "\n",
    "plt.scatter(y_act, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a3c220",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_sel, y_sel = ds_sel[:len(ds_sel)]\n",
    "\n",
    "with torch.no_grad():\n",
    "    Z_sel = model_sel.basis(X_sel)\n",
    "    Zpred = torch.zeros(len(Z_sel), K_sel)\n",
    "    for i in model_sel.basis.order[:2]:\n",
    "        Zpred[:, i] = Z_sel[:,i]\n",
    "\n",
    "with torch.no_grad():\n",
    "    f_sel = model_sel.surface(Zpred)\n",
    "\n",
    "with torch.no_grad():\n",
    "    Y = f_sel.mean.numpy()\n",
    "\n",
    "plt.scatter(y_sel, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cf05f5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_act.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b76d8bb",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "f_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1dcff0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_preact = torch.stack([ds_act.tokenizer.tokenize(x) for x in test_set['description']])\n",
    "X_presel = torch.stack([ds_sel.tokenizer.tokenize(x) for x in test_set['description']])\n",
    "\n",
    "with torch.no_grad():\n",
    "    Z_preact = model_act.basis(X_preact)\n",
    "\n",
    "with torch.no_grad():\n",
    "    Z_presel = model_sel.basis(X_presel)\n",
    "\n",
    "with torch.no_grad():\n",
    "    f_preact = model_act.surface(Z_preact)\n",
    "\n",
    "with torch.no_grad():\n",
    "    f_presel = model_sel.surface(Z_presel)\n",
    "    \n",
    "with torch.no_grad():\n",
    "    Y_act = f_preact.mean.numpy()\n",
    "\n",
    "with torch.no_grad():\n",
    "    Y_sel = f_presel.mean.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2d7cd4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.scatter(Y_act,Y_sel)\n",
    "plt.xlabel(\"pre_act(log)\")\n",
    "plt.ylabel(\"pre_sel(log)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3fb978",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_preact = torch.stack([ds_act.tokenizer.tokenize(x) for x in test_set['description']])\n",
    "X_presel = torch.stack([ds_sel.tokenizer.tokenize(x) for x in test_set['description']])\n",
    "\n",
    "Y_act_total = np.zeros(len(Y_act))\n",
    "Y_sel_total = np.zeros(len(Y_sel))\n",
    "\n",
    "for i in range(10):\n",
    "    with torch.no_grad():\n",
    "        Z_preact = model_act.basis(X_preact)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        Z_presel = model_sel.basis(X_presel)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        f_preact = model_act.surface(Z_preact)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        f_presel = model_sel.surface(Z_presel)\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        Y_act_total += f_preact.mean.numpy()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        Y_sel_total += f_presel.mean.numpy()\n",
    "\n",
    "Y_act_mean = Y_act_total / 10\n",
    "Y_sel_mean = Y_sel_total / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e671716",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.scatter(Y_act_mean,Y_sel_mean)\n",
    "plt.xlabel(\"pre_act(log)\")\n",
    "plt.ylabel(\"pre_sel(log)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac049fb1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_preact = torch.stack([ds_act.tokenizer.tokenize(x) for x in test_set['description']])\n",
    "X_presel = torch.stack([ds_sel.tokenizer.tokenize(x) for x in test_set['description']])\n",
    "\n",
    "Y_act_total = np.zeros(len(Y_act))\n",
    "Y_sel_total = np.zeros(len(Y_sel))\n",
    "\n",
    "n = 100\n",
    "\n",
    "for i in range(n):\n",
    "    with torch.no_grad():\n",
    "        Z_preact = model_act.basis(X_preact)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        Z_presel = model_sel.basis(X_presel)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        f_preact = model_act.surface(Z_preact)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        f_presel = model_sel.surface(Z_presel)\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        Y_act_total += f_preact.mean.numpy()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        Y_sel_total += f_presel.mean.numpy()\n",
    "\n",
    "Y_act_mean = Y_act_total / n\n",
    "Y_sel_mean = Y_sel_total / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703d4830",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.scatter(Y_act_mean,Y_sel_mean)\n",
    "plt.xlabel(\"pre_act(log)\")\n",
    "plt.ylabel(\"pre_sel(log)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabd54e4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_set['Activity'] = np.exp(Y_act_mean)\n",
    "test_set['Selectivity'] = np.exp(Y_sel_mean)\n",
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511d5cae",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.scatter(test_set['Activity'], test_set['Selectivity'])\n",
    "plt.xlabel(\"pre_act\")\n",
    "plt.ylabel(\"pre_sel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e31fcf",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_set[['SequenceID', 'Sequence', 'Activity', 'Selectivity']].to_csv('test_set_prediction.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bab1b6e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "7 scanning best 96 sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e5f537",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "aa_multiple = [x+y for x in aa_order for y in aa_order]\n",
    "aa_three = [x+y for x in aa_order for y in aa_multiple]\n",
    "aa_four = [x+y for x in aa_multiple for y in aa_multiple]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e64b2f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_seq = list(training_df['Sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4573897a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mutate(seq, letter, num):\n",
    "    return seq[:num] + letter + seq[num+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8b9f20",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a26eeae",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_act = pd.DataFrame()\n",
    "temp_sel = pd.DataFrame()\n",
    "\n",
    "for i in itertools.combinations([0,1,2,3,4,5],r = 2):\n",
    "    test_list = []\n",
    "    for turn, aaa in enumerate(aa_three):\n",
    "        seq = prime_seq\n",
    "        for times,mut_site in enumerate(i):\n",
    "            seq = mutate(seq, aaa[times], mut_site)\n",
    "        \n",
    "        if seq not in train_seq:\n",
    "            test_list.append(seq)\n",
    "    \n",
    "    test_df = pd.DataFrame(test_list, columns = ['Sequence'])\n",
    "    test_df['description'] = test_df['Sequence'].apply(lambda x:get_seq_description(x))\n",
    "\n",
    "    X_preact = torch.stack([ds_act.tokenizer.tokenize(x) for x in test_df['description']])\n",
    "    X_presel = torch.stack([ds_sel.tokenizer.tokenize(x) for x in test_df['description']])\n",
    "\n",
    "    Y_act_total = np.zeros(len(test_df))\n",
    "    Y_sel_total = np.zeros(len(test_df))\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        Z_preact = model_act.basis(X_preact)\n",
    "        Z_presel = model_sel.basis(X_presel)\n",
    "        f_preact = model_act.surface(Z_preact)\n",
    "        f_presel = model_sel.surface(Z_presel)\n",
    "        Y_act = f_preact.mean.numpy()\n",
    "        Y_sel = f_presel.mean.numpy()\n",
    "\n",
    "    test_df['Activity'] = np.exp(Y_act)\n",
    "    test_df['Selectivity'] = np.exp(Y_sel)\n",
    "\n",
    "    temp_act2 = test_df.sort_values(by = 'Activity', ascending = False).head(50)\n",
    "    temp_act = temp_act.append(temp_act2).sort_values(by = 'Activity', ascending = False).head(50)\n",
    "\n",
    "    temp_sel2 = test_df.sort_values(by = 'Selectivity', ascending = False).head(50)\n",
    "    temp_sel = temp_sel.append(temp_sel2).sort_values(by = 'Selectivity', ascending = False).head(50)\n",
    "\n",
    "    print(i, list(temp_act['Activity'][:3]),list(temp_sel['Selectivity'][:3])) \n",
    "\n",
    "temp_act_2 = temp_act.copy()\n",
    "temp_sel_2 = temp_sel.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005a8767",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_act = pd.DataFrame()\n",
    "temp_sel = pd.DataFrame()\n",
    "\n",
    "for i in itertools.combinations([0,1,2,3,4,5],r = 3):\n",
    "    test_list = []\n",
    "    for turn, aaa in enumerate(aa_three):\n",
    "        seq = prime_seq\n",
    "        for times,mut_site in enumerate(i):\n",
    "            seq = mutate(seq, aaa[times], mut_site)\n",
    "        \n",
    "        if seq not in train_seq:\n",
    "            test_list.append(seq)\n",
    "    \n",
    "    test_df = pd.DataFrame(test_list, columns = ['Sequence'])\n",
    "    test_df['description'] = test_df['Sequence'].apply(lambda x:get_seq_description(x))\n",
    "\n",
    "    X_preact = torch.stack([ds_act.tokenizer.tokenize(x) for x in test_df['description']])\n",
    "    X_presel = torch.stack([ds_sel.tokenizer.tokenize(x) for x in test_df['description']])\n",
    "\n",
    "    Y_act_total = np.zeros(len(test_df))\n",
    "    Y_sel_total = np.zeros(len(test_df))\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        Z_preact = model_act.basis(X_preact)\n",
    "        Z_presel = model_sel.basis(X_presel)\n",
    "        f_preact = model_act.surface(Z_preact)\n",
    "        f_presel = model_sel.surface(Z_presel)\n",
    "        Y_act = f_preact.mean.numpy()\n",
    "        Y_sel = f_presel.mean.numpy()\n",
    "\n",
    "    test_df['Activity'] = np.exp(Y_act)\n",
    "    test_df['Selectivity'] = np.exp(Y_sel)\n",
    "\n",
    "    temp_act2 = test_df.sort_values(by = 'Activity', ascending = False).head(50)\n",
    "    temp_act = temp_act.append(temp_act2).sort_values(by = 'Activity', ascending = False).head(50)\n",
    "\n",
    "    temp_sel2 = test_df.sort_values(by = 'Selectivity', ascending = False).head(50)\n",
    "    temp_sel = temp_sel.append(temp_sel2).sort_values(by = 'Selectivity', ascending = False).head(50)\n",
    "\n",
    "    print(i, list(temp_act['Activity'][:3]),list(temp_sel['Selectivity'][:3])) \n",
    "\n",
    "temp_act_3 = temp_act.copy()\n",
    "temp_sel_3 = temp_sel.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50163dd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_act = pd.DataFrame()\n",
    "temp_sel = pd.DataFrame()\n",
    "\n",
    "for turn, aaa in enumerate(aa_four):\n",
    "    if turn < 27000:\n",
    "        pass\n",
    "    else:\n",
    "        \n",
    "        test_list = []\n",
    "        for i in itertools.combinations([0,1,2,3,4,5],r = 4):\n",
    "            seq = prime_seq\n",
    "            for times,mut_site in enumerate(i):\n",
    "                seq = mutate(seq, aaa[times], mut_site)\n",
    "            \n",
    "            if seq not in train_seq:\n",
    "                test_list.append(seq)\n",
    "        \n",
    "        test_df = pd.DataFrame(test_list, columns = ['Sequence'])\n",
    "        test_df['description'] = test_df['Sequence'].apply(lambda x:get_seq_description(x))\n",
    "\n",
    "        X_preact = torch.stack([ds_act.tokenizer.tokenize(x) for x in test_df['description']])\n",
    "        X_presel = torch.stack([ds_sel.tokenizer.tokenize(x) for x in test_df['description']])\n",
    "\n",
    "        Y_act_total = np.zeros(len(test_df))\n",
    "        Y_sel_total = np.zeros(len(test_df))\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            Z_preact = model_act.basis(X_preact)\n",
    "            Z_presel = model_sel.basis(X_presel)\n",
    "            f_preact = model_act.surface(Z_preact)\n",
    "            f_presel = model_sel.surface(Z_presel)\n",
    "            Y_act = f_preact.mean.numpy()\n",
    "            Y_sel = f_presel.mean.numpy()\n",
    "\n",
    "        test_df['Activity'] = np.exp(Y_act)\n",
    "        test_df['Selectivity'] = np.exp(Y_sel)\n",
    "\n",
    "        temp_act2 = test_df.sort_values(by = 'Activity', ascending = False).head(50)\n",
    "        temp_act = temp_act.append(temp_act2).sort_values(by = 'Activity', ascending = False).head(50)\n",
    "\n",
    "        temp_sel2 = test_df.sort_values(by = 'Selectivity', ascending = False).head(50)\n",
    "        temp_sel = temp_sel.append(temp_sel2).sort_values(by = 'Selectivity', ascending = False).head(50)\n",
    "\n",
    "        # print(i, list(temp_act['Activity'][:3]),list(temp_sel['Selectivity'][:3])) \n",
    "        print(turn,aaa)\n",
    "\n",
    "temp_act_4_2 = temp_act.copy()\n",
    "temp_sel_4_2 = temp_sel.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf36d63",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_act_all = temp_act_2.append(temp_act_3).sort_values(by = 'Activity', ascending = False).head(50)\n",
    "temp_sel_all = temp_sel_2.append(temp_sel_3).sort_values(by = 'Selectivity', ascending = False).head(50)\n",
    "\n",
    "temp_act_all = temp_act_all.append(temp_act_4_2).sort_values(by = 'Activity', ascending = False).head(50)\n",
    "temp_sel_all = temp_sel_all.append(temp_sel_4_2).sort_values(by = 'Selectivity', ascending = False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fe2181",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_act_all['cotE'] = temp_act_all['Sequence'].apply(lambda x:x[2] not in [\"I\", \"K\", \"M\"])\n",
    "temp_sel_all['cotE'] = temp_sel_all['Sequence'].apply(lambda x:x[2] not in [\"I\", \"K\", \"M\"])\n",
    "\n",
    "temp_act_all[temp_act_all['cotE']].to_csv('act_screen_234_withoutE.csv')\n",
    "temp_sel_all[temp_sel_all['cotE']].to_csv('sel_screen_234_withoutE.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snakemake",
   "language": "python",
   "name": "snakemake"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 0.445794,
   "end_time": "2023-10-26T14:21:56.269001",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-26T14:21:55.823207",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
